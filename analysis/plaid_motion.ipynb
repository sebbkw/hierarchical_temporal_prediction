{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import torch\n",
    "import pingouin as pg\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "\n",
    "from plaid_data import plaid_data\n",
    "PI_dist_V1 = plaid_data['PI_dist_V1']\n",
    "PI_dist_V2 = plaid_data['PI_dist_V2']\n",
    "PI_dist_MT = plaid_data['PI_dist_MT']\n",
    "\n",
    "# Import custom modules\n",
    "sys.path.append(\"../\")\n",
    "from models.network_hierarchical_recurrent import NetworkHierarchicalRecurrent\n",
    "from models.network_feedforward_stacked import NetworkFeedforwardStacked\n",
    "from virtual_physiology_20x40.VirtualNetworkPhysiology import VirtualPhysiology\n",
    "from plotting_functions import *\n",
    "\n",
    "COLORS = ['tab:blue', 'tab:red', 'tab:green', 'tab:gray']\n",
    "\n",
    "def not_nan (arr):\n",
    "    return [a for a in arr if not np.isnan(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = ''\n",
    "VPHYS_PATH = ''\n",
    "UNITS      = 800\n",
    "\n",
    "# Load model\n",
    "model, hyperparameters, loss_history = NetworkHierarchicalRecurrent.load(\n",
    "    model_path=MODEL_PATH,\n",
    "    device='cpu',\n",
    "    plot_loss_history=False\n",
    ")\n",
    "\n",
    "# Load previously processed vphys data\n",
    "vphys = VirtualPhysiology.load(\n",
    "    data_path=VPHYS_PATH,\n",
    "    model=model,\n",
    "    hyperparameters=hyperparameters,\n",
    "    hidden_units=[UNITS, UNITS, UNITS],\n",
    "    frame_shape=(20, 40),\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "physiology_data_group1 = vphys.data[0]\n",
    "physiology_data_group2 = vphys.data[1]\n",
    "physiology_data_group3 = vphys.data[2]\n",
    "\n",
    "# Global vars\n",
    "FRAME_SIZE           = hyperparameters[\"frame_size\"]\n",
    "WARMUP               = hyperparameters[\"warmup\"]\n",
    "T_STEPS              = 40\n",
    "TEMPORAL_FREQUENCIES = vphys.temporal_frequencies\n",
    "SPATIAL_FREQUENCIES  = vphys.spatial_frequencies\n",
    "ORIENTATIONS         = vphys.orientations\n",
    "FRAME_SHAPE          = (20, 40)\n",
    "\n",
    "COLORS = ['tab:blue', 'tab:red', 'tab:green', 'tab:gray']\n",
    "\n",
    "HEIGHT, WIDTH = FRAME_SHAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean plaid tuning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DSI (tuning_curve):\n",
    "    orient_pref_idx = np.argmax(tuning_curve)\n",
    "    orient_pref = np.max(tuning_curve)\n",
    "    \n",
    "    orient_opp_idx = (orient_pref_idx + len(tuning_curve)//2) % len(tuning_curve)\n",
    "    orient_opp = tuning_curve[orient_opp_idx]\n",
    "\n",
    "    DSI = (orient_pref - orient_opp) / (orient_pref + orient_opp)\n",
    "\n",
    "    return DSI\n",
    "    \n",
    "plaid_selective_DSI_all = []\n",
    "    \n",
    "for group in vphys.data:\n",
    "    plaid_selective_units = [u for u in group if u['plaid_pattern_index']>0]\n",
    "    plaid_selective_DSI = [get_DSI(u['plaid_response']) for u in plaid_selective_units]\n",
    "    plaid_selective_DSI_all += plaid_selective_DSI\n",
    "    \n",
    "    DS_pct = round(len([u for u in plaid_selective_DSI if u>0.3])/len(plaid_selective_DSI) * 100, 2)\n",
    "    \n",
    "    print(len(plaid_selective_DSI), '\\t', DS_pct, '%', '\\t', np.mean(plaid_selective_DSI))\n",
    "    \n",
    "print(\n",
    "    round(len([u for u in plaid_selective_DSI_all if u>0.3])/len(plaid_selective_DSI_all) * 100, 2),\n",
    "    '\\t', \n",
    "    np.mean(plaid_selective_DSI_all)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution with and without feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_nofb, hyperparameters, _ = NetworkHierarchicalRecurrent.load(\n",
    "    model_path=MODEL_PATH, device='cpu'\n",
    ")\n",
    "\n",
    "pct_inactivated = 1\n",
    "mask_1 = np.random.choice([0,1], size=(800, 800), p=[pct_inactivated,1-pct_inactivated])\n",
    "mask_2 = np.random.choice([0,1], size=(800, 800), p=[pct_inactivated,1-pct_inactivated])\n",
    "weights = model.rnn.weight_hh_l0.detach().cpu().numpy().copy()\n",
    "weights[0:800, 800:1600] = weights[0:800, 800:1600]*mask_1\n",
    "weights[800:1600, 1600:2400] = weights[800:1600, 1600:2400]*mask_2\n",
    "model_nofb.rnn.weight_hh_l0 = torch.nn.Parameter(torch.Tensor(weights).to('cpu'))\n",
    "\n",
    "# Instantiate new VirtualPhysiology object\n",
    "vphys_nofb = VirtualPhysiology.load(\n",
    "    data_path=VPHYS_PATH,\n",
    "    model=model_nofb,\n",
    "    hyperparameters=hyperparameters,\n",
    "    frame_shape=(20, 40),\n",
    "    hidden_units=[800, 800, 800],\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "vphys_nofb.get_plaid_pattern_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = not_nan([u['plaid_pattern_index'] for u in vphys.data[0]])\n",
    "nofb = not_nan([u['plaid_pattern_index'] for u in vphys_nofb.data[0]])\n",
    "\n",
    "mn = np.array([\n",
    "    np.mean(full),\n",
    "    np.mean(nofb)\n",
    "])\n",
    "er = np.array([\n",
    "    np.std(full)/(len(full)**2),\n",
    "    np.mean(nofb)/(len(nofb)**2),\n",
    "])\n",
    "\n",
    "x = np.array([0, 1])\n",
    "labels = ['Full model', 'No feedback']\n",
    "c = [COLORS[0], COLORS[0]]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.bar(x, mn, yerr=er)\n",
    "plt.xticks(x, labels)\n",
    "format_plot(fontsize=20)\n",
    "fig.set_size_inches((4, 4))\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "vp = plt.violinplot([full, nofb], x, showmedians=False, showextrema=False)\n",
    "plt.xticks(x, labels)\n",
    "for i, pc in enumerate(vp[\"bodies\"], 0):\n",
    "    pc.set_facecolor(c[i])\n",
    "    pc.set_edgecolor('black')\n",
    "    pc.set_alpha(0.8)\n",
    "plt.hlines(mn, x-0.5, x+0.5, linewidth=2, color='black', zorder=3, alpha=0.8)\n",
    "plt.ylabel('Plaid pattern index')\n",
    "format_plot(fontsize=20)\n",
    "fig.set_size_inches(5, 4)\n",
    "plt.savefig(f'./figures/plaid_response/nofb_mean_multicompangle.pdf', bbox_inches='tight')\n",
    "plt.show()  \n",
    "\n",
    "pg.ttest(full, nofb, paired=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centre_shift (arr, axis, shift=False):\n",
    "    arr = np.array(arr)\n",
    "    \n",
    "    if not shift:\n",
    "        max_idx = np.argmax(arr, axis=axis)\n",
    "        max_idx = stats.mode(max_idx).mode[0]\n",
    "        shift = int(np.ceil(arr.shape[axis]/2) - max_idx)\n",
    "    \n",
    "    return np.roll(arr, shift, axis=axis), shift\n",
    "\n",
    "group_idx = 0\n",
    "\n",
    "plaid_ori_list = np.arange(0, 360, 20)\n",
    "centred_plaid_ori_list = np.arange(-180, 180, 20)\n",
    "delta_ori_list = [0, 30, 60, 90, 120, 150]\n",
    "\n",
    "units = [*vphys.data[0], *vphys.data[2]]\n",
    "\n",
    "c = 0\n",
    "\n",
    "for vphys_to_use, model_to_use in zip([vphys, vphys_nofb], [model, model_nofb]):\n",
    "\n",
    "    for unit_i, unit in enumerate(units):   \n",
    "        if not unit['hidden_unit_index'] in [2079]: # 2079\n",
    "            continue\n",
    "\n",
    "        print('Starting unit ', unit['hidden_unit_index'])\n",
    "\n",
    "        response_curves_list = []\n",
    "\n",
    "        for delta_ori in delta_ori_list:\n",
    "            response_curve = []\n",
    "            for plaid_ori in plaid_ori_list:\n",
    "                ori_a = plaid_ori - delta_ori//2\n",
    "                ori_b = plaid_ori + delta_ori//2\n",
    "\n",
    "                grating_a = vphys_to_use.get_grating_stimuli(unit['preferred_sf'], ori_a, unit['preferred_tf'], 1, 50)\n",
    "                grating_b = vphys_to_use.get_grating_stimuli(unit['preferred_sf'], ori_b, unit['preferred_tf'], 1, 50)\n",
    "                plaid = grating_a+grating_b\n",
    "                #plaid = (plaid-torch.mean(plaid))/torch.std(plaid)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    _, h = model_to_use(plaid)\n",
    "\n",
    "                mean_res = np.mean(h[0, WARMUP:, unit['hidden_unit_index']].detach().numpy(), axis=0)\n",
    "                response_curve.append( mean_res )\n",
    "\n",
    "            if delta_ori == 0:\n",
    "                shifted_curve, shift = centre_shift(response_curve, axis=0, shift=False)\n",
    "            else:\n",
    "                shifted_curve, _ = centre_shift(response_curve, axis=0, shift=shift)\n",
    "\n",
    "            response_curves_list.append(shifted_curve)\n",
    "\n",
    "        fig = plt.figure()\n",
    "\n",
    "        for curve, delta in zip(response_curves_list, delta_ori_list):\n",
    "            plt.plot(centred_plaid_ori_list, curve, label=delta)\n",
    "        plt.ylabel('Unit response')\n",
    "        plt.xlabel('Orientation (°)')\n",
    "        format_plot(fontsize=20)\n",
    "        fig.set_size_inches(4, 4)\n",
    "        plt.gca().get_legend().set_visible(False)\n",
    "        plt.show()\n",
    "\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern index distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_dist = not_nan([u['plaid_pattern_index'] for u in vphys.data[0]])\n",
    "g2_dist = not_nan([u['plaid_pattern_index'] for u in vphys.data[1]])\n",
    "g3_dist = not_nan([u['plaid_pattern_index'] for u in vphys.data[2]])\n",
    "\n",
    "\n",
    "labels = ['$\\mathregular{G_1}$', 'V1', '$\\mathregular{G_2}$', 'V2', '$\\mathregular{G_3}$', 'MT']\n",
    "all_dists = [g1_dist, PI_dist_V1, g2_dist, PI_dist_V2, g3_dist, PI_dist_MT]\n",
    "c = [COLORS[0], 'grey', [168/255,199/255,218/255], 'grey', [213/255,227/255,237/255], 'grey']\n",
    "\n",
    "means = [np.mean(g1_dist), np.mean(PI_dist_V1),  np.mean(g2_dist), np.mean(PI_dist_V2), np.mean(g3_dist), np.mean(PI_dist_MT)]\n",
    "\n",
    "x = np.array([0, 1, 2.5, 3.5, 5, 6])\n",
    "\n",
    "fig = plt.figure()\n",
    "vp = plt.violinplot(all_dists, x, showmedians=False, showextrema=False)\n",
    "plt.xticks(x, labels)\n",
    "for i, pc in enumerate(vp[\"bodies\"], 0):\n",
    "    pc.set_facecolor(c[i])\n",
    "    pc.set_edgecolor('black')\n",
    "    pc.set_alpha(0.8)\n",
    "plt.hlines(means, x-0.5, x+0.5, linewidth=2, color='black', zorder=3, alpha=0.8)\n",
    "plt.ylabel('Plaid pattern index')\n",
    "format_plot(fontsize=20)\n",
    "fig.set_size_inches(8, 4)\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_df = {\n",
    "    'group': [],\n",
    "    'plaid_index': []\n",
    "}\n",
    "for g_idx, g in enumerate([g1_dist, g2_dist, g3_dist]):\n",
    "    anova_df['group'] += list(np.ones(len(g))*g_idx)\n",
    "    anova_df['plaid_index'] += list(g)\n",
    "display(pg.anova(data=pd.DataFrame(anova_df), dv='plaid_index', between='group'))\n",
    "\n",
    "anova_df = {\n",
    "    'group': [],\n",
    "    'plaid_index': []\n",
    "}\n",
    "for g_idx, g in enumerate([PI_dist_V1, PI_dist_V2, PI_dist_MT]):\n",
    "    anova_df['group'] += list(np.ones(len(g))*g_idx)\n",
    "    anova_df['plaid_index'] += list(g)\n",
    "display(pg.anova(data=pd.DataFrame(anova_df), dv='plaid_index', between='group'))\n",
    "\n",
    "p_vals = []\n",
    "label_combos = []\n",
    "for combo in combinations(zip(labels, all_dists), 2): \n",
    "    a, b = combo\n",
    "    a_label, a_dist = a\n",
    "    b_label, b_dist = b\n",
    "    \n",
    "    ttest = stats.ttest_ind(a_dist, b_dist)\n",
    "    print(a_label, 'vs', b_label, '\\t\\t', ttest)\n",
    "    \n",
    "    p_vals.append(ttest[1])\n",
    "    label_combos.append(f'{a_label} vs {b_label}')\n",
    "\n",
    "p_vals_corr = pg.multicomp(p_vals, method='holm')\n",
    "    \n",
    "print('\\n')\n",
    "for pair, p_t, p_v in zip(label_combos, p_vals_corr[0], p_vals_corr[1]):\n",
    "    print(pair, '\\t', p_t, '\\t', p_v)\n",
    "\n",
    "print('\\n')\n",
    "print(np.mean(g1_dist), np.mean(g2_dist), np.mean(g3_dist), np.mean(PI_dist_V1), np.mean(PI_dist_V2), np.mean(PI_dist_MT))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_nan (arr):\n",
    "    return [a for a in arr if not np.isnan(a)]\n",
    "\n",
    "TP_model, hyperparameters, loss_history = NetworkHierarchicalRecurrent.load(\n",
    "    model_path='',\n",
    "    device='cpu',\n",
    "    plot_loss_history=False\n",
    ")\n",
    "TP_vphys = VirtualPhysiology.load(\n",
    "    data_path='',\n",
    "    model=TP_model,\n",
    "    hyperparameters=hyperparameters,\n",
    "    hidden_units=[800, 800, 800],\n",
    "    frame_shape=(20, 40),\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "TP_ff_model = NetworkFeedforwardStacked([])\n",
    "TP_ff_vphys = VirtualPhysiology.load(\n",
    "    data_path='',\n",
    "    model=TP_ff_model,\n",
    "    hyperparameters=TP_ff_model.stacks[0].hyperparameters,\n",
    "    hidden_units=[800, 800, 800],\n",
    "    frame_shape=(20, 40),\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "AE_model, hyperparameters, loss_history = NetworkHierarchicalRecurrent.load(\n",
    "    model_path='',\n",
    "    device='cpu',\n",
    "    plot_loss_history=False\n",
    ")\n",
    "AE_vphys = VirtualPhysiology.load(\n",
    "    data_path='',\n",
    "    model=AE_model,\n",
    "    hyperparameters=hyperparameters,\n",
    "    hidden_units=[800, 800, 800],\n",
    "    frame_shape=(20, 40),\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "\n",
    "all_model_dists = []\n",
    "\n",
    "ks_dist = []\n",
    "\n",
    "for vphys_i, (vphys, color) in enumerate(zip([TP_vphys, TP_ff_vphys, AE_vphys], COLORS)):\n",
    "    g1_dist = not_nan([u['plaid_pattern_index'] for u in vphys.data[0]])\n",
    "    g2_dist = not_nan([u['plaid_pattern_index'] for u in vphys.data[1]])\n",
    "    g3_dist = not_nan([u['plaid_pattern_index'] for u in vphys.data[2]])\n",
    "\n",
    "    all_model_dists.append([g1_dist, g2_dist, g3_dist])\n",
    "    \n",
    "    labels = ['$\\mathregular{G_{1}}$', 'V1', '$\\mathregular{G_{2}}$', 'V2', '$\\mathregular{G_{3}}$', 'MT']\n",
    "    all_dists = [g1_dist, PI_dist_V1, g2_dist, PI_dist_V2, g3_dist, PI_dist_MT]\n",
    "    c = [color, 'grey', color, 'grey', color, 'grey']\n",
    "\n",
    "    means = [np.mean(g1_dist), np.mean(PI_dist_V1),  np.mean(g2_dist), np.mean(PI_dist_V2), np.mean(g3_dist), np.mean(PI_dist_MT)]\n",
    "\n",
    "    x = np.array([0, 1, 3, 4, 6, 7])\n",
    "\n",
    "    fig = plt.figure()\n",
    "    vp = plt.violinplot(all_dists, x, showmedians=False, showextrema=False)\n",
    "    plt.xticks(x, labels)\n",
    "    for i, pc in enumerate(vp[\"bodies\"], 0):\n",
    "        pc.set_facecolor(c[i])\n",
    "        pc.set_edgecolor('black')\n",
    "        pc.set_alpha(0.8)\n",
    "    plt.hlines(means, x-0.5, x+0.5, linewidth=2, color='black', zorder=3, alpha=0.8)\n",
    "    if vphys_i == '':\n",
    "        plt.ylabel('Plaid pattern index')\n",
    "    format_plot(fontsize=20)\n",
    "    fig.set_size_inches(4, 4)\n",
    "    plt.ylim(-12.5, 12.5)\n",
    "    plt.savefig(f'./figures/model_comparison/B_{[\"i\", \"ii\", \"iii\"][vphys_i]}_multicompangle.pdf', bbox_inches='tight')\n",
    "    plt.show()  \n",
    "    \n",
    "    ks_dist.append([\n",
    "        stats.ks_2samp(g1_dist, PI_dist_V1)[0],\n",
    "        stats.ks_2samp(g2_dist, PI_dist_V2)[0],\n",
    "        stats.ks_2samp(g3_dist, PI_dist_MT)[0]\n",
    "    ])\n",
    "    \n",
    "    p_vals = []\n",
    "    label_combos = []\n",
    "    for combo in combinations(zip(labels, all_dists), 2): \n",
    "        a, b = combo\n",
    "        a_label, a_dist = a\n",
    "        b_label, b_dist = b\n",
    "\n",
    "        ttest = stats.ttest_ind(a_dist, b_dist)\n",
    "        print(a_label, 'vs', b_label, '\\t\\t', ttest)\n",
    "\n",
    "        p_vals.append(ttest[1])\n",
    "        label_combos.append(f'{a_label} vs {b_label}')\n",
    "\n",
    "    \n",
    "x = [0, 1, 2]\n",
    "fig = plt.figure()\n",
    "b = plt.bar(x, [np.mean(d) for d in ks_dist], yerr=[np.std(d)/(len(d)**0.5) for d in ks_dist], facecolor='tab:gray')\n",
    "for b_i, c_i in zip(b, COLORS):\n",
    "    b_i.set_facecolor(c_i)\n",
    "plt.xticks(x, ['$\\mathregular{TP_{full}}$', '$\\mathregular{TP_{FF}}$', 'AE'], rotation=0)\n",
    "plt.ylabel('KS distance')\n",
    "format_plot(fontsize=20)\n",
    "fig.set_size_inches(3, 4)\n",
    "plt.savefig(f'./figures/model_comparison/B_iv_multicompangle.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contour plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centre_shift (arr, axis):\n",
    "    max_idx = np.argmax(arr, axis=axis)\n",
    "    max_idx = stats.mode(max_idx).mode[0]\n",
    "    shift = int(np.ceil(arr.shape[axis]/2) - 1 - max_idx)\n",
    "    \n",
    "    return np.roll(arr, shift, axis=axis)\n",
    "\n",
    "a = np.arange(0, 360, 25)\n",
    "b = np.arange(0, 360, 25)\n",
    "\n",
    "units = [*vphys.data[0], *vphys.data[2]]\n",
    "\n",
    "c = 0\n",
    "\n",
    "for unit_i, unit in enumerate(units):\n",
    "    if not unit['hidden_unit_index'] in [8, 585]: # 2079\n",
    "        continue \n",
    "        \n",
    "    print('Starting unit ', unit['hidden_unit_index'])\n",
    "    contour = np.zeros(shape=(len(a), len(b)))\n",
    "    for a_idx, a_i in enumerate(a):\n",
    "        print('\\tProcessing orientation', a_i, 'degrees')\n",
    "        for b_idx, b_i in enumerate(b):\n",
    "            grating_a = vphys.get_grating_stimuli(unit['preferred_sf'], a_i, unit['preferred_tf'], 1, 50)\n",
    "            grating_b = vphys.get_grating_stimuli(unit['preferred_sf'], b_i, unit['preferred_tf'], 1, 50)\n",
    "            \n",
    "            plaid = grating_a+grating_b\n",
    "            plaid = (plaid-torch.mean(plaid))/torch.std(plaid)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                _, h = model(plaid)\n",
    "\n",
    "\n",
    "            mean_res = np.mean(h[0, WARMUP:, unit['hidden_unit_index']].detach().numpy(), axis=0)\n",
    "            contour[a_idx, b_idx] = mean_res\n",
    "\n",
    "    contour = centre_shift(contour, 0)\n",
    "    contour = centre_shift(contour, 1)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.contourf(np.arange(-180, 180, 25), np.arange(-180, 180, 25), contour)\n",
    "    plt.xlabel('B orientation (°)')\n",
    "    plt.ylabel('A orientation (°)')\n",
    "    format_plot(fontsize=20)\n",
    "    fig.set_size_inches(3, 3)\n",
    "    plt.savefig(f'./figures/plaid_response/c_{\"\".join(np.repeat(\"i\", c+1))}.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centre_shift (arr, axis, shift=False):\n",
    "    arr = np.array(arr)\n",
    "    \n",
    "    if not shift:\n",
    "        max_idx = np.argmax(arr, axis=axis)\n",
    "        max_idx = stats.mode(max_idx).mode[0]\n",
    "        shift = int(np.ceil(arr.shape[axis]/2) - max_idx)\n",
    "    \n",
    "    return np.roll(arr, shift, axis=axis), shift\n",
    "\n",
    "group_idx = 0\n",
    "\n",
    "plaid_ori_list = np.arange(0, 360, 20)\n",
    "centred_plaid_ori_list = np.arange(-180, 180, 20)\n",
    "delta_ori_list = [0, 30, 60, 90, 120, 150]\n",
    "\n",
    "units = [*vphys.data[0], *vphys.data[2]]\n",
    "\n",
    "c = 0\n",
    "\n",
    "for unit_i, unit in enumerate(units):   \n",
    "    if not unit['hidden_unit_index'] in [8, 585]: # 2079\n",
    "        continue\n",
    "        \n",
    "    print('Starting unit ', unit['hidden_unit_index'])\n",
    "    \n",
    "    response_curves_list = []\n",
    "    \n",
    "    for delta_ori in delta_ori_list:\n",
    "        response_curve = []\n",
    "        for plaid_ori in plaid_ori_list:\n",
    "            ori_a = plaid_ori - delta_ori//2\n",
    "            ori_b = plaid_ori + delta_ori//2\n",
    "\n",
    "            grating_a = vphys.get_grating_stimuli(unit['preferred_sf'], ori_a, unit['preferred_tf'], 1, 50)\n",
    "            grating_b = vphys.get_grating_stimuli(unit['preferred_sf'], ori_b, unit['preferred_tf'], 1, 50)\n",
    "            plaid = grating_a+grating_b\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                _, h = model(plaid)\n",
    "\n",
    "            mean_res = np.mean(h[0, WARMUP:, unit['hidden_unit_index']].detach().numpy(), axis=0)\n",
    "            response_curve.append( mean_res )\n",
    "            \n",
    "        if delta_ori == 0:\n",
    "            shifted_curve, shift = centre_shift(response_curve, axis=0, shift=False)\n",
    "        else:\n",
    "            shifted_curve, _ = centre_shift(response_curve, axis=0, shift=shift)\n",
    "        \n",
    "        response_curves_list.append(shifted_curve)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    for curve, delta in zip(response_curves_list, delta_ori_list):\n",
    "        plt.plot(centred_plaid_ori_list, curve, label=delta)\n",
    "    plt.ylabel('Unit response')\n",
    "    plt.xlabel('Orientation (°)')\n",
    "    format_plot(fontsize=20)\n",
    "    fig.set_size_inches(3, 3)\n",
    "    plt.gca().get_legend().set_visible(False)\n",
    "    plt.savefig(f'./figures/plaid_response/d_{\"\".join(np.repeat(\"i\", c+1))}.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    c += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:allensdk]",
   "language": "python",
   "name": "conda-env-allensdk-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from skimage.filters import butterworth\n",
    "import skimage.filters as filters\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "import pingouin as pg\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "\n",
    "# Import custom modules\n",
    "sys.path.append(\"../\")\n",
    "from models.network_hierarchical_recurrent   import NetworkHierarchicalRecurrent\n",
    "from models.network_hierarchical_feedforward import NetworkHierarchicalFeedforward\n",
    "from data.dataset                            import data_loader\n",
    "\n",
    "from plotting_functions import *\n",
    "\n",
    "indist_data_loader = data_loader(\n",
    "    '', #Â dir path\n",
    "    split='validation',\n",
    "    batch_size=200,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "outdist_data_loader = data_loader(\n",
    "    '', # dir path\n",
    "    split='train',\n",
    "    batch_size=200,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_broken_bar (x_label, mean, error, facecolor, offset=-1):\n",
    "    x = np.arange(len(x_label))\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "\n",
    "    ax1.bar(x, mean, yerr=error, facecolor=facecolor)\n",
    "    ax2.bar(x, mean, yerr=error, facecolor=facecolor)\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(x_label, rotation=45)\n",
    "\n",
    "    format_plot(ax1, fontsize=20)\n",
    "    format_plot(ax2, fontsize=20)\n",
    "    \n",
    "    ax1.set_ylim(min(mean[offset:])-max(error[offset:])-0.03, max(mean[offset:])+max(error[offset:])+0.03)\n",
    "    ax2.set_ylim(min(mean)-0.05, max(mean[:offset])+0.05) \n",
    "\n",
    "\n",
    "    ax1.spines['bottom'].set_visible(False)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax1.set_xticks([])\n",
    "    ax1.tick_params(labeltop=False)\n",
    "    ax2.xaxis.tick_bottom()\n",
    "\n",
    "\n",
    "    #determine axes and their limits \n",
    "    ax_selec = [(ax, ax.get_ylim()) for ax in [ax1, ax2]]\n",
    "    #find maximum y-limit spread\n",
    "    max_delta = max([lmax-lmin for _, (lmin, lmax) in ax_selec]) \n",
    "    #expand limits of all subplots according to maximum spread\n",
    "    for ax, (lmin, lmax) in ax_selec:\n",
    "        d = max_delta\n",
    "        ax.set_ylim(lmin-(max_delta-(lmax-lmin))/2, lmax+(max_delta-(lmax-lmin))/2)\n",
    "\n",
    "\n",
    "    d = .015  \n",
    "    kwargs = dict(transform=ax1.transAxes, color='k', clip_on=False)\n",
    "    ax1.plot((-d, +d), (-d, +d), **kwargs)\n",
    "    kwargs.update(transform=ax2.transAxes)\n",
    "    ax2.plot((-d, +d), (1 - d, 1 + d), **kwargs) \n",
    "\n",
    "    fig.set_size_inches(4,4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model path data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to trained model checkpoints here\n",
    "\n",
    "model_beta = {\n",
    "    0   : {},\n",
    "    0.05: {},\n",
    "    0.1 : {},\n",
    "    0.25: {},\n",
    "    0.5 : {}\n",
    "}\n",
    "model_architecture = {\n",
    "    'Hierarchical': {},\n",
    "    'Vanilla RNN' : {},\n",
    "    'Feedforward' : {}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next-frame prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_mse (data):\n",
    "    MSE = (np.diff(data[0], axis=1)**2).mean(axis=2).mean(axis=1)\n",
    "    \n",
    "    return data[0][MSE>1], data[1][MSE>1]\n",
    "\n",
    "def low_pass (data, freq):\n",
    "    return [\n",
    "        torch.tensor([\n",
    "            [\n",
    "                butterworth(i.detach().cpu().numpy().reshape(20, 20), cutoff_frequency_ratio=freq, high_pass=False).reshape(-1)\n",
    "                for i in c\n",
    "            ]\n",
    "            for c in d\n",
    "        ])\n",
    "        for d in data\n",
    "    ]\n",
    "\n",
    "def low_pass (data, freq):\n",
    "    d_ = []\n",
    "    for d in data:\n",
    "        c_ = []\n",
    "        for c in d:\n",
    "            thresh = threshold_otsu(c)\n",
    "            c_.append([f>thresh for f in c])\n",
    "        d_.append(c_)\n",
    "        \n",
    "    print(torch.tensor(d_)).shape\n",
    "        \n",
    "    return torch.tensor(d_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mse (model, data_loader):\n",
    "    mse_arr = []\n",
    "    \n",
    "    model.eval()\n",
    "    for batch_n, data in enumerate(data_loader):        \n",
    "        if batch_n%5==0:\n",
    "            print('\\tStarting batch', batch_n)\n",
    "        \n",
    "        if batch_n > 19:\n",
    "            break\n",
    "        \n",
    "        y = data[0]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            out = model(y)\n",
    "            loss, loss_components = model.get_loss(out, data)\n",
    "            \n",
    "        mse_arr.append(loss_components['mse0'].tolist())\n",
    "            \n",
    "    return np.mean(mse_arr), np.std(mse_arr)/(len(mse_arr)**0.5), mse_arr\n",
    "\n",
    "def get_mse_copy_last_frame (data_loader):\n",
    "    mse_arr = []\n",
    "    \n",
    "    for batch_n, data in enumerate(data_loader):\n",
    "        #data = filter_mse(data)\n",
    "        \n",
    "        if batch_n%5==0:\n",
    "            print('\\tStarting batch', batch_n)\n",
    "        \n",
    "        y = data[0]\n",
    "                    \n",
    "        mse_arr += ((y[:, 1:]-y[:, :-1, :400])**2).detach().cpu().numpy().mean(axis=1).mean(axis=1).tolist()\n",
    "            \n",
    "    return np.mean(mse_arr), np.std(mse_arr)/(len(mse_arr)**0.5), mse_arr\n",
    "\n",
    "def get_mse_by_model (model_data, data_loader, plot_by_L1=False):\n",
    "    root  = '' # checkpoints dir\n",
    "    epoch = 2000\n",
    "\n",
    "    model_nm_arr = []\n",
    "    model_mn_arr  = []\n",
    "    model_er_arr  = []\n",
    "    model_rw_arr  = []\n",
    "\n",
    "    for model_name, model_paths in model_data.items():\n",
    "        L1_arr   = []\n",
    "        mn_arr  = []\n",
    "        er_arr  = []\n",
    "        rw_arr  = []\n",
    "\n",
    "        for L1, folder in model_paths.items():\n",
    "            file = f'{root}{folder}/{epoch}-epochs_model.pt'\n",
    "            print(file)\n",
    "            \n",
    "            try:\n",
    "                if 'feedforward' in file:\n",
    "                    raise Exception\n",
    "                model, _, _ = NetworkHierarchicalRecurrent.load(\n",
    "                    model_path=file, device='cpu', plot_loss_history=False\n",
    "                )\n",
    "            except:\n",
    "                model, _, _ = NetworkHierarchicalFeedforward.load(\n",
    "                    model_path=file, device='cpu', plot_loss_history=False\n",
    "                )            \n",
    "\n",
    "            mn, er, rw = get_mse(model, data_loader)\n",
    "            L1_arr.append(L1)\n",
    "            mn_arr.append(mn)\n",
    "            er_arr.append(er)\n",
    "            rw_arr.append(rw)\n",
    "            \n",
    "        if plot_by_L1:\n",
    "            plt.errorbar(L1_arr, mn_arr, yerr=er_arr)\n",
    "            plt.xlabel('L1')\n",
    "            plt.ylabel('MSE')\n",
    "            format_plot()\n",
    "            plt.show()\n",
    "\n",
    "        model_nm_arr.append(model_name)\n",
    "        model_mn_arr.append(np.min(mn_arr))\n",
    "        model_er_arr.append(er_arr[np.argmin(mn_arr)])\n",
    "        model_rw_arr.append(rw_arr[np.argmin(mn_arr)])\n",
    "        \n",
    "    copy_mn, copy_er, copy_rw = get_mse_copy_last_frame (data_loader)\n",
    "    model_nm_arr.append('Copy frame')\n",
    "    model_mn_arr.append(copy_mn)\n",
    "    model_er_arr.append(copy_er)\n",
    "    model_rw_arr.append(copy_rw)\n",
    "    \n",
    "    return model_nm_arr, model_mn_arr, model_er_arr, model_rw_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_SIZE = 20\n",
    "\n",
    "def get_COM (im, rotation):\n",
    "    im = im.reshape(20, 20)**4\n",
    "    \n",
    "    com = (\n",
    "        np.average(np.arange(0, im.shape[0]), weights=im.mean(axis=1)),\n",
    "        np.average(np.arange(0, im.shape[1]), weights=im.mean(axis=0))\n",
    "    )\n",
    "\n",
    "    theta = np.deg2rad(rotation)\n",
    "    com_rot = (\n",
    "        np.sin(theta) * (com[1]-10) + np.cos(theta) * (com[0]-10) + 10,\n",
    "        np.cos(theta) * (com[1]-10) - np.sin(theta) * (com[0]-10) + 10,\n",
    "    )\n",
    "\n",
    "    return com_rot[1]\n",
    "\n",
    "\n",
    "def whiten_and_filter_image (im_to_filt):\n",
    "    Nx, Ny = im_to_filt.shape\n",
    "    imf = np.fft.fftshift(np.fft.fft2(im_to_filt))\n",
    "    fx = np.arange(-Nx/2, Nx/2)\n",
    "    fy = np.arange(-Ny/2, Ny/2)\n",
    "    [fx, fy] = np.meshgrid(fx,fy)\n",
    "    rho = np.sqrt(fx**2 + fy**2)\n",
    "    filtf = rho*np.exp(-0.5*(rho/(0.7*max(Nx, Ny)/2))**2)\n",
    "    imwf = filtf.T*imf\n",
    "    imw = np.real(np.fft.ifft2(np.fft.fftshift(imwf)))\n",
    "    return imw\n",
    "\n",
    "def get_bar_stimuli (rotate=0, w=3):\n",
    "    im_arr = []\n",
    "    for i in range(FRAME_SIZE):\n",
    "        im = np.zeros((FRAME_SIZE*2, FRAME_SIZE*2))\n",
    "        im[:, FRAME_SIZE//2+i:FRAME_SIZE//2+i+w] = 1\n",
    "        im = whiten_and_filter_image(im)\n",
    "        im = ndimage.rotate(im, rotate, reshape=False)\n",
    "        im_arr.append(im[FRAME_SIZE//2:-FRAME_SIZE//2, FRAME_SIZE//2:-FRAME_SIZE//2].reshape(-1))\n",
    "        \n",
    "    im_arr = np.array(im_arr)\n",
    "    im_arr = (im_arr-np.mean(im_arr))/np.std(im_arr)\n",
    "    im_arr = torch.from_numpy(im_arr)\n",
    "        \n",
    "    return im_arr.float()\n",
    "\n",
    "def get_mse_bar_copy_last_frame (warmup=10, tsteps=9):\n",
    "    mse_arr = []\n",
    "\n",
    "    for rotation in np.arange(0, 360, 45):\n",
    "        x = get_bar_stimuli(rotation)\n",
    "\n",
    "        y     = x[warmup:warmup+tsteps]\n",
    "        y_hat = x[warmup:warmup+1     ].repeat((tsteps, 1))\n",
    "    \n",
    "        mse_arr += ((y-y_hat)**2).detach().cpu().numpy().mean(axis=1).tolist()\n",
    "            \n",
    "    return np.mean(mse_arr), np.std(mse_arr)/(len(mse_arr)**0.5), mse_arr\n",
    "\n",
    "def get_mse_bar_rnn (model, hierarchical=False, warmup=10, tsteps=9):\n",
    "    model.eval()\n",
    "    mse_arr = []\n",
    "    com_arr = []\n",
    "\n",
    "    for rotation in np.arange(0, 360, 22.5):\n",
    "        x = get_bar_stimuli(rotation)\n",
    "        o = []\n",
    "\n",
    "        targ = []\n",
    "        pred = []\n",
    "\n",
    "        if hierarchical:\n",
    "            h = [torch.zeros((1, FRAME_SIZE*FRAME_SIZE*2*3))]\n",
    "        else:\n",
    "            h = [torch.zeros((1, FRAME_SIZE*FRAME_SIZE*2))]\n",
    "\n",
    "        for t, x_t in enumerate(x):\n",
    "            if t+1>=warmup+tsteps:\n",
    "                break\n",
    "\n",
    "            if t+1>=warmup:\n",
    "                h_t, _ = model.rnn(o[-1].unsqueeze(0), h[-1])\n",
    "            else:\n",
    "                h_t, _ = model.rnn(x_t.unsqueeze(0), h[-1])            \n",
    "            o_t    = model.fc(h_t)[:, :FRAME_SIZE*FRAME_SIZE]\n",
    "\n",
    "            h.append(h_t)\n",
    "            o.append(o_t[0])\n",
    "            \n",
    "            if t+1>=warmup:\n",
    "                targ.append(x[t+1].detach().numpy())\n",
    "                pred.append(o_t[0].detach().numpy())\n",
    "                        \n",
    "        mse_arr += [np.mean((t-p)**2) for t, p in zip(targ, pred)]\n",
    "        com_arr += [np.abs(get_COM(t, rotation)-get_COM(p, rotation)) for t, p in zip(targ, pred)]\n",
    "        \n",
    "        if False:\n",
    "            fig, axs = plt.subplots(nrows=2, ncols=tsteps, dpi=150, figsize=[tsteps, 2])\n",
    "            for i, (t, p) in enumerate(zip(targ, pred)):\n",
    "                axs[0, i].imshow(t.reshape(FRAME_SIZE, FRAME_SIZE))\n",
    "                axs[0, i].set_xticks([])\n",
    "                axs[0, i].set_yticks([])\n",
    "                axs[1, i].imshow(p.reshape(FRAME_SIZE, FRAME_SIZE))\n",
    "                axs[1, i].set_xticks([])\n",
    "                axs[1, i].set_yticks([])\n",
    "                \n",
    "                if i >= warmup:\n",
    "                    axs[1, i].set_xlabel(f't+{i-warmup}')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show  \n",
    "            \n",
    "    mse_mn = np.mean(mse_arr)\n",
    "    mse_er = np.std(mse_arr)/(len(mse_arr)**0.5)\n",
    "    \n",
    "    com_mn = np.mean(com_arr)\n",
    "    com_er = np.std(com_arr)/(len(com_arr)**0.5)\n",
    "    \n",
    "    return mse_mn, mse_er, mse_arr, com_mn, com_er, com_arr\n",
    "\n",
    "def get_mse_bar_ff (model, warmup=10, tsteps=9):\n",
    "    model.eval()\n",
    "    model.hidden_units_groups = model.hidden_units_groups[:1]\n",
    "\n",
    "    mse_arr = []\n",
    "    com_arr = []\n",
    "\n",
    "    for rotation in np.arange(0, 360, 45):\n",
    "        x = get_bar_stimuli(rotation).unsqueeze(0)\n",
    "\n",
    "        targ = []\n",
    "        pred = []\n",
    "\n",
    "        p_t = model(x[:, :warmup])[0][0]\n",
    "            \n",
    "        for t in range(tsteps):\n",
    "            p_t1 = model(p_t)[0][0][:, -1:]\n",
    "            p_t = torch.cat([p_t, p_t1], dim=1)\n",
    "            \n",
    "            pred.append(p_t[0, 0].detach().numpy())\n",
    "            targ.append(x[:, warmup+t+1].detach().numpy())\n",
    "\n",
    "        mse_arr += [np.mean((t-p)**2) for t, p in zip(targ, pred)]\n",
    "        com_arr += [np.abs(get_COM(t, rotation)-get_COM(p, rotation)) for t, p in zip(targ, pred)]\n",
    "        \n",
    "        if False:\n",
    "            fig, axs = plt.subplots(nrows=2, ncols=tsteps, dpi=150, figsize=[tsteps, 2])\n",
    "            for i, (t, p) in enumerate(zip(targ, pred)):\n",
    "                axs[0, i].imshow(t.reshape(FRAME_SIZE, FRAME_SIZE))\n",
    "                axs[0, i].set_xticks([])\n",
    "                axs[0, i].set_yticks([])\n",
    "                axs[1, i].imshow(p.reshape(FRAME_SIZE, FRAME_SIZE))\n",
    "                axs[1, i].set_xticks([])\n",
    "                axs[1, i].set_yticks([])\n",
    "                \n",
    "                if i >= warmup:\n",
    "                    axs[1, i].set_xlabel(f't+{i-warmup}')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show  \n",
    "            \n",
    "    mse_mn = np.mean(mse_arr)\n",
    "    mse_er = np.std(mse_arr)/(len(mse_arr)**0.5)\n",
    "    \n",
    "    com_mn = np.mean(com_arr)\n",
    "    com_er = np.std(com_arr)/(len(com_arr)**0.5)\n",
    "    \n",
    "    return mse_mn, mse_er, mse_arr, com_mn, com_er, com_arr\n",
    "\n",
    "def get_mse_by_model_bar (model_data, plot_by_L1=False, copy_frame=True):\n",
    "    root  = '' # checkpoint dir\n",
    "    epoch = 2000\n",
    "\n",
    "    model_name_arr     = []\n",
    "    model_mse_mn_arr   = []\n",
    "    model_mse_er_arr   = []\n",
    "    model_mse_raw_arr  = []\n",
    "    model_com_mn_arr   = []\n",
    "    model_com_er_arr   = []\n",
    "    model_com_raw_arr  = []\n",
    "\n",
    "    for model_name, model_paths in model_data.items():\n",
    "        L1_arr      = []\n",
    "        mse_mn_arr  = []\n",
    "        mse_er_arr  = []\n",
    "        mse_raw_arr = []\n",
    "        com_mn_arr  = []\n",
    "        com_er_arr  = []\n",
    "        com_raw_arr = []\n",
    "        \n",
    "        for L1, folder in model_paths.items():\n",
    "            file = f'{root}{folder}/{epoch}-epochs_model.pt'\n",
    "            print(file)\n",
    "\n",
    "            try:\n",
    "                if 'feedforward' in file:\n",
    "                    raise Exception\n",
    "                model, _, _ = NetworkHierarchicalRecurrent.load(\n",
    "                    model_path=file, device='cpu', plot_loss_history=False\n",
    "                )\n",
    "            except:\n",
    "                model, _, _ = NetworkHierarchicalFeedforward.load(\n",
    "                    model_path=file, device='cpu', plot_loss_history=False\n",
    "                )            \n",
    "\n",
    "            if hasattr(model, 'ih0'):\n",
    "                mse_mn, mse_er, mse_raw, com_mn, com_er, com_raw = get_mse_bar_ff(model)\n",
    "            else:\n",
    "                is_hierarchical = model.rnn.weight_ih_l0.shape[0] == 20*20*2*3\n",
    "                mse_mn, mse_er, mse_raw, com_mn, com_er, com_raw = get_mse_bar_rnn(model, hierarchical=is_hierarchical)\n",
    "                \n",
    "            L1_arr.append(L1)\n",
    "            mse_mn_arr.append(mse_mn)\n",
    "            mse_er_arr.append(mse_er)\n",
    "            mse_raw_arr.append(mse_raw)\n",
    "            com_mn_arr.append(com_mn)\n",
    "            com_er_arr.append(com_er)\n",
    "            com_raw_arr.append(com_raw)\n",
    "        \n",
    "        if plot_by_L1:\n",
    "            plt.errorbar(L1_arr, mse_arr, yerr=err_arr)\n",
    "            plt.xlabel('L1')\n",
    "            plt.ylabel('MSE')\n",
    "            format_plot()\n",
    "            plt.show()\n",
    "\n",
    "        model_name_arr.append(model_name)\n",
    "        model_mse_mn_arr.append(np.min(mse_mn_arr))\n",
    "        model_mse_er_arr.append(mse_er_arr[np.argmin(mse_mn_arr)])\n",
    "        model_mse_raw_arr.append(mse_raw_arr[np.argmin(mse_mn_arr)])\n",
    "        model_com_mn_arr.append(np.min(com_mn_arr))\n",
    "        model_com_er_arr.append(mse_er_arr[np.argmin(com_mn_arr)])\n",
    "        model_com_raw_arr.append(mse_raw_arr[np.argmin(com_mn_arr)])\n",
    "\n",
    "        \n",
    "    if copy_frame:\n",
    "        copy_mn, copy_er, copy_rw = get_mse_bar_copy_last_frame (warmup=10, tsteps=9)\n",
    "        model_name_arr.append('Copy frame')\n",
    "        model_mse_mn_arr.append(copy_mn)\n",
    "        model_mse_er_arr.append(copy_er)\n",
    "        model_mse_raw_arr.append(copy_rw)\n",
    "        \n",
    "    return model_name_arr, model_mse_mn_arr, model_mse_er_arr, model_mse_raw_arr, model_com_mn_arr, model_com_er_arr, model_com_raw_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_arr, indist_mn_arr, indist_er_arr, indist_raw_arr = \\\n",
    "    get_mse_by_model (model_architecture, indist_data_loader, plot_by_L1=False)\n",
    "\n",
    "model_name_arr, outdist_mn_arr, outdist_er_arr, outdist_raw_arr = \\\n",
    "    get_mse_by_model (model_architecture, outdist_data_loader, plot_by_L1=False)\n",
    "\n",
    "bar_model_name_arr, bar_mn_arr, bar_er_arr, bar_raw_arr, _, _, _ = \\\n",
    "    get_mse_by_model_bar (model_architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_broken_bar (x_label, mean, error, facecolor, offset=-1):\n",
    "    x = np.arange(len(x_label))\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "\n",
    "    ax1.bar(x, mean, yerr=error, facecolor=facecolor)\n",
    "    ax2.bar(x, mean, yerr=error, facecolor=facecolor)\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(x_label, rotation=45)\n",
    "\n",
    "    format_plot(ax1, fontsize=20)\n",
    "    format_plot(ax2, fontsize=20)\n",
    "    \n",
    "    ax1.set_ylim(min(mean[offset:])-max(error[offset:])-0.08, max(mean[offset:])+max(error[offset:])+0.0)\n",
    "    ax2.set_ylim(min(mean)-0.075, max(mean[:offset])+0.025) \n",
    "\n",
    "\n",
    "    ax1.spines['bottom'].set_visible(False)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax1.set_xticks([])\n",
    "    ax1.tick_params(labeltop=False)\n",
    "    ax2.xaxis.tick_bottom()\n",
    "\n",
    "\n",
    "    #determine axes and their limits \n",
    "    ax_selec = [(ax, ax.get_ylim()) for ax in [ax1, ax2]]\n",
    "    #find maximum y-limit spread\n",
    "    max_delta = max([lmax-lmin for _, (lmin, lmax) in ax_selec]) \n",
    "    #expand limits of all subplots according to maximum spread\n",
    "    for ax, (lmin, lmax) in ax_selec:\n",
    "        d = max_delta\n",
    "        ax.set_ylim(lmin-(max_delta-(lmax-lmin))/2, lmax+(max_delta-(lmax-lmin))/2)\n",
    "\n",
    "\n",
    "    d = .015  \n",
    "    kwargs = dict(transform=ax1.transAxes, color='k', clip_on=False)\n",
    "    ax1.plot((-d, +d), (-d, +d), **kwargs)\n",
    "    kwargs.update(transform=ax2.transAxes)\n",
    "    ax2.plot((-d, +d), (1 - d, 1 + d), **kwargs) \n",
    "\n",
    "    fig.set_size_inches(3,4)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "fig = plot_broken_bar (model_name_arr, indist_mn_arr, indist_er_arr, 'tab:gray')\n",
    "plt.show()\n",
    "\n",
    "fig = plot_broken_bar (model_name_arr, outdist_mn_arr, outdist_er_arr, 'tab:gray')\n",
    "plt.show()\n",
    "\n",
    "fig = plot_broken_bar (bar_model_name_arr, bar_mn_arr, bar_er_arr, 'tab:gray', offset=-2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_model_name_arr, bar_mse_mn, bar_mse_er, bar_mse_raw, bar_com_mn, bar_com_er, _ = \\\n",
    "    get_mse_by_model_bar (model_beta, copy_frame=False)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.errorbar(bar_model_name_arr, bar_mse_mn, yerr=bar_mse_er, c='black')\n",
    "plt.plot([0, bar_model_name_arr[-1]], [bar_mse_mn[0], bar_mse_mn[0]], '--', c='black')\n",
    "plt.xlabel('Beta')\n",
    "plt.ylabel('Multi-frame MSE')\n",
    "format_plot(fontsize=20)\n",
    "fig.set_size_inches(3, 4)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.errorbar(bar_model_name_arr, bar_com_mn, yerr=bar_com_er, c='black')\n",
    "plt.plot([0, bar_model_name_arr[-1]], [bar_com_mn[0], bar_com_mn[0]], '--', c='black')\n",
    "plt.xlabel('Beta')\n",
    "plt.ylabel('Centre-of-mass MAE')\n",
    "format_plot(fontsize=20)\n",
    "fig.set_size_inches(3, 4)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = plt.gca()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "ax1.errorbar(bar_model_name_arr, bar_mse_mn, yerr=bar_mse_er, c='tab:blue')\n",
    "ax2.errorbar(bar_model_name_arr, bar_com_mn, yerr=bar_com_er, c='tab:orange')\n",
    "ax1.set_xlabel('Beta')\n",
    "ax1.set_ylabel('Multi-frame MSE', color='tab:blue')\n",
    "ax2.set_ylabel('Centre-of-mass MAE', color='tab:orange')\n",
    "\n",
    "format_plot(ax1, fontsize=20)\n",
    "format_plot(ax2, fontsize=20)\n",
    "ax2.spines['right'].set_visible(True)\n",
    "fig.set_size_inches(3, 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_model_name_arr, indist_mn_arr, indist_er_arr, indist_raw_arr = \\\n",
    "    get_mse_by_model (model_beta, indist_data_loader, plot_by_L1=False)\n",
    "\n",
    "bar_model_name_arr, outdist_mn_arr, outdist_er_arr, outdist_raw_arr = \\\n",
    "    get_mse_by_model (model_beta, outdist_data_loader, plot_by_L1=False)\n",
    "\n",
    "bar_model_name_arr = bar_model_name_arr[:-1]\n",
    "indist_mn_arr = indist_mn_arr[:-1]\n",
    "indist_er_arr = indist_er_arr[:-1]\n",
    "indist_raw_arr = indist_raw_arr[:-1]\n",
    "outdist_mn_arr = outdist_mn_arr[:-1]\n",
    "outdist_er_arr = outdist_er_arr[:-1]\n",
    "outdist_raw_arr = outdist_raw_arr[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.errorbar(bar_model_name_arr, indist_mn_arr, yerr=indist_er_arr, c='black')\n",
    "plt.plot([0, bar_model_name_arr[-1]], [indist_mn_arr[0], indist_mn_arr[0]], '--', c='tab:gray')\n",
    "plt.xlabel('Beta')\n",
    "plt.ylabel('Nex-frame MSE')\n",
    "format_plot(fontsize=20)\n",
    "fig.set_size_inches(4, 4)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.errorbar(bar_model_name_arr, outdist_mn_arr, yerr=outdist_er_arr, c='black')\n",
    "plt.plot([0, bar_model_name_arr[-1]], [outdist_mn_arr[0], outdist_mn_arr[0]], '--', c='tab:gray')\n",
    "plt.xlabel('Beta')\n",
    "plt.ylabel('Nex-frame MSE')\n",
    "format_plot(fontsize=20)\n",
    "fig.set_size_inches(4, 4)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:allensdk]",
   "language": "python",
   "name": "conda-env-allensdk-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
